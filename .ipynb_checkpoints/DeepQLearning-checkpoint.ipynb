{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f1a166",
   "metadata": {},
   "source": [
    "# Deep Q Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f76c0",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697eec7",
   "metadata": {},
   "source": [
    "This notebook reproduce the DeepQLearning network and then use this algorithm to control \"CartPole\" game.\n",
    "\n",
    "Also, this code refers [MorvanZhou](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5_Deep_Q_Network/DQN_modified.py) and [ljp](https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/dqn.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73d3a7",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "176993fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0553d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e6eaa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf8626",
   "metadata": {},
   "source": [
    "## Code Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9948b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQLearning:\n",
    "    def __init__(self, n_features, n_actions, learning_rate = 0.01 ,reward_decay = 0.9, e_greedy = 0.9, memory_size = 500, batch_size = 32):\n",
    "        self.n_features = n_features\n",
    "        self.n_actions = n_actions\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon = e_greedy\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        self._build_network()\n",
    "        \n",
    "        self._train_network()\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        self.memory = np.zeros((memory_size, 2 * n_features + 2))\n",
    "        self.memory_counter = 0 \n",
    "        \n",
    "        \n",
    "    def _build_network(self):\n",
    "        self.observations = tf.placeholder(tf.float32, shape = (None, self.n_features))\n",
    "        \n",
    "        tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1)\n",
    "        # DNN network\n",
    "        fc1 = tf.layers.dense(self.observations, 8, tf.nn.relu, \n",
    "                              kernel_initializer=tf.random_normal_initializer(0., 0.3), \n",
    "                              bias_initializer=tf.constant_initializer(0.1))\n",
    "        self.q_eval = tf.layers.dense(fc1, self.n_actions,  \n",
    "                              kernel_initializer=tf.random_normal_initializer(0., 0.3), \n",
    "                              bias_initializer=tf.constant_initializer(0.1))\n",
    "      \n",
    "    def _train_network(self):\n",
    "        \n",
    "        self.actions = tf.placeholder(tf.int32, shape = (None,))\n",
    "        \n",
    "        self.rewards = tf.placeholder(tf.int32, shape = (None,))\n",
    "        \n",
    "        # Q(S',argmax_A(S',A))\n",
    "        self.q_next = tf.placeholder(tf.float32, shape = (None,))\n",
    "        \n",
    "        hot_code_actions = tf.one_hot(self.actions, self.n_actions)\n",
    "        \n",
    "        # Q(S,A)\n",
    "        q_eval = tf.reduce_sum(tf.multiply(self.q_eval, hot_code_actions), axis = 1)\n",
    "    \n",
    "        loss = tf.losses.mean_squared_error(labels = self.q_next + tf.cast(self.rewards, tf.float32), predictions = q_eval)\n",
    "        \n",
    "        self.train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "    \n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        now = np.hstack([s, [a, r], s_])\n",
    "        \n",
    "        if self.memory_counter < self.memory_size:\n",
    "            self.memory[self.memory_counter] = now\n",
    "        else:\n",
    "            index = self.memory_counter % self.memory_size\n",
    "            self.memory[index] = now\n",
    "        \n",
    "        self.memory_counter += 1\n",
    "    \n",
    "    def train(self):\n",
    "        if self.memory_counter > self.memory_size:\n",
    "            sample_index = np.random.choice(self.memory_size, size = self.batch_size)\n",
    "        else:\n",
    "            sample_index = np.random.choice(self.memory_counter, size = self.batch_size)\n",
    "            \n",
    "        batch_memory = self.memory[sample_index, :]\n",
    "        \n",
    "        s = batch_memory[:, :self.n_features]\n",
    "        \n",
    "        a = batch_memory[:, self.n_features]\n",
    "        \n",
    "        r = batch_memory[:, self.n_features+1]\n",
    "        \n",
    "        s_ = batch_memory[:, self.n_features+2:]\n",
    "                \n",
    "        q_next_eval = np.zeros_like(r)\n",
    "        \n",
    "        eval_sample = []\n",
    "        \n",
    "        for i in range(q_next_eval.shape[0]):\n",
    "            if not True in np.isnan(s_[i]):\n",
    "                eval_sample.append(i)\n",
    "        \n",
    "        # eval the actions\n",
    "        eval_Q = self.sess.run(self.q_eval, feed_dict = {\n",
    "            self.observations: s_[eval_sample]\n",
    "        })\n",
    "\n",
    "        # choose best actions\n",
    "        \n",
    "        q_next_eval[eval_sample] = np.max(eval_Q, axis = 1)  \n",
    "       \n",
    "        # learning from data\n",
    "        self.sess.run(self.train_op, feed_dict = {\n",
    "            self.observations: s,\n",
    "            self.actions: a,\n",
    "            self.rewards: r,\n",
    "            self.q_next: q_next_eval,\n",
    "        })\n",
    "        \n",
    "    def predict(self, s):\n",
    "        \n",
    "        # eplison - greedy\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            Q = self.sess.run(self.q_eval, feed_dict = {\n",
    "            self.observations : s[np.newaxis, :]\n",
    "        })\n",
    "            return np.argmax(Q)\n",
    "        else:\n",
    "            return np.random.randint(self.n_actions)\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7727de",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50136009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e87eb55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON_NUM = 30\n",
    "THRESHOLD = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02edc0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d102074",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0p/g6nj5mqd3xl8lx0bpcg9f4nw0000gn/T/ipykernel_52740/2364555404.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mreset_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m   6040\u001b[0m   \"\"\"\n\u001b[1;32m   6041\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cleared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6042\u001b[0;31m     raise AssertionError(\"Do not use tf.reset_default_graph() to clear \"\n\u001b[0m\u001b[1;32m   6043\u001b[0m                          \u001b[0;34m\"nested graphs. If you need a cleared graph, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6044\u001b[0m                          \"exit the nesting and create a new graph.\")\n",
      "\u001b[0;31mAssertionError\u001b[0m: Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6aacf4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to capture an EagerTensor without building a function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0p/g6nj5mqd3xl8lx0bpcg9f4nw0000gn/T/ipykernel_52740/2161485964.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepQLearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/0p/g6nj5mqd3xl8lx0bpcg9f4nw0000gn/T/ipykernel_52740/1506953533.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_features, n_actions, learning_rate, reward_decay, e_greedy, memory_size, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/0p/g6nj5mqd3xl8lx0bpcg9f4nw0000gn/T/ipykernel_52740/1506953533.py\u001b[0m in \u001b[0;36m_train_network\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_next\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstore_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    418\u001b[0m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n\u001b[0m\u001b[1;32m    421\u001b[0m                                 name=name)\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, global_step, name)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;34m\"update_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscope_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             skip_on_eager=False), ops.colocate_with(var):\n\u001b[0;32m--> 624\u001b[0;31m           \u001b[0mupdate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0mapply_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mupdate_op\u001b[0;34m(self, optimizer, g)\u001b[0m\n\u001b[1;32m    177\u001b[0m       return optimizer._resource_apply_sparse_duplicate_indices(\n\u001b[1;32m    178\u001b[0m           g.values, self._v, g.indices)\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/training/adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"v\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mbeta1_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2_power\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_beta_accumulators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     return training_ops.resource_apply_adam(\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/ops/gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[1;32m   1442\u001b[0m     \u001b[0muse_nesterov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m   \u001b[0muse_nesterov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_nesterov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_nesterov\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   1445\u001b[0m         \u001b[0;34m\"ResourceApplyAdam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1_power\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta1_power\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                              \u001b[0mbeta2_power\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta2_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    515\u001b[0m                   preferred_dtype=default_dtype)\n\u001b[1;32m    516\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             values = ops.convert_to_tensor(\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1523\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[0m\u001b[1;32m   1526\u001b[0m                            \"building a function.\")\n\u001b[1;32m   1527\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to capture an EagerTensor without building a function."
     ]
    }
   ],
   "source": [
    "model = DeepQLearning(n_actions = env.action_space.n, n_features = env.observation_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a5cb91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0005265  -0.15344673  0.04717619  0.31150812]\n",
      "[-0.00359544 -0.34920794  0.05340636  0.61868787]\n",
      "[-0.0105796  -0.5450336   0.06578011  0.9277016 ]\n",
      "[-0.02148027 -0.7409791   0.08433414  1.2403095 ]\n",
      "[-0.03629985 -0.9370765   0.10914034  1.5581752 ]\n",
      "[-0.05504138 -1.133323    0.14030384  1.8828169 ]\n",
      "[-0.07770784 -1.3296661   0.17796017  2.2155519 ]\n",
      "[-0.10430116 -1.5259888   0.22227122  2.5574296 ]\n",
      "[ 0.00845116 -0.17191142 -0.02345716  0.2672434 ]\n",
      "[ 0.00501293 -0.36669087 -0.01811229  0.5524364 ]\n",
      "[-0.00232089 -0.56155384 -0.00706356  0.8393582 ]\n",
      "[-0.01355196 -0.7565786   0.00972361  1.1298114 ]\n",
      "[-0.02868354 -0.9518266   0.03231983  1.4255282 ]\n",
      "[-0.04772007 -1.1473327   0.0608304   1.7281346 ]\n",
      "[-0.07066672 -1.3430948   0.09539309  2.0391078 ]\n",
      "[-0.09752861 -1.5390601   0.13617525  2.3597224 ]\n",
      "[-0.12830982 -1.7351091   0.1833697   2.6909854 ]\n",
      "[-0.163012  -1.9310374  0.2371894  3.0335598]\n",
      "[ 0.02622542 -0.16632874 -0.02603409  0.29898548]\n",
      "[ 0.02289885 -0.3610701  -0.02005438  0.5833454 ]\n",
      "[ 0.01567744 -0.55590546 -0.00838747  0.86964405]\n",
      "[ 0.00455933 -0.7509123   0.00900541  1.1596781 ]\n",
      "[-0.01045891 -0.9461504   0.03219898  1.455171  ]\n",
      "[-0.02938192 -1.1416525   0.0613024   1.757737  ]\n",
      "[-0.05221497 -1.337413    0.09645714  2.068838  ]\n",
      "[-0.07896323 -1.5333745   0.1378339   2.3897283 ]\n",
      "[-0.10963072 -1.729412    0.18562846  2.7213905 ]\n",
      "[-0.14421897 -1.9253136   0.24005626  3.0644565 ]\n",
      "[-0.04058798 -0.21660446 -0.00337548  0.28736138]\n",
      "[-0.04492006 -0.4116781   0.00237175  0.5789778 ]\n",
      "[-0.05315363 -0.6068332   0.01395131  0.87240696]\n",
      "[-0.06529029 -0.8021421   0.03139945  1.1694432 ]\n",
      "[-0.08133313 -0.9976581   0.05478831  1.4718026 ]\n",
      "[-0.10128629 -1.1934055   0.08422437  1.7810829 ]\n",
      "[-0.1251544  -1.3893678   0.11984602  2.0987172 ]\n",
      "[-0.15294176 -1.5854733   0.16182037  2.4259157 ]\n",
      "[-0.18465123 -1.7815781   0.21033868  2.763598  ]\n",
      "[ 0.0082719  -0.17154294 -0.02232017  0.3104761 ]\n",
      "[ 0.00484104 -0.3663399  -0.01611065  0.59603715]\n",
      "[-0.00248576 -0.56123275 -0.0041899   0.88360214]\n",
      "[-0.01371042 -0.7562975   0.01348214  1.1749649 ]\n",
      "[-0.02883637 -0.951592    0.03698144  1.4718437 ]\n",
      "[-0.04786821 -0.7569413   0.06641831  1.1909373 ]\n",
      "[-0.06300703 -0.95285803  0.09023706  1.503677  ]\n",
      "[-0.0820642 -0.7589396  0.1203106  1.2404766]\n",
      "[-0.09724299 -0.9553832   0.14512013  1.568298  ]\n",
      "[-0.11635065 -1.1519096   0.17648609  1.9025046 ]\n",
      "[-0.13938884 -1.3484471   0.21453618  2.2443495 ]\n",
      "[-0.0185428  -0.14751633  0.04475584  0.31554148]\n",
      "[-0.02149313 -0.34324628  0.05106667  0.6219962 ]\n",
      "[-0.02835806 -0.5390427   0.0635066   0.9303151 ]\n",
      "[-0.03913891 -0.7349617   0.0821129   1.2422595 ]\n",
      "[-0.05383814 -0.93103594  0.10695809  1.559494  ]\n",
      "[-0.07245886 -1.1272632   0.13814797  1.8835387 ]\n",
      "[-0.09500413 -1.3235923   0.17581874  2.215713  ]\n",
      "[-0.12147597 -1.5199068   0.220133    2.5570698 ]\n",
      "[ 0.02161632 -0.18572117 -0.01000576  0.33635557]\n",
      "[ 0.0179019  -0.3806993  -0.00327865  0.6258665 ]\n",
      "[ 0.01028791 -0.5757753   0.00923868  0.91751504]\n",
      "[-0.00122759 -0.77102095  0.02758898  1.2130871 ]\n",
      "[-0.01664801 -0.9664879   0.05185072  1.514286  ]\n",
      "[-0.03597777 -1.1621977   0.08213644  1.8226936 ]\n",
      "[-0.05922173 -0.96807814  0.11859031  1.5566168 ]\n",
      "[-0.07858329 -1.1644042   0.14972265  1.8838214 ]\n",
      "[-0.10187137 -1.3608053   0.18739907  2.2189813 ]\n",
      "[-0.12908748 -1.5571586   0.2317787   2.5631282 ]\n",
      "[-0.01764727 -0.15922956  0.02668666  0.2667584 ]\n",
      "[-0.02083186 -0.35472202  0.03202183  0.56773764]\n",
      "[-0.0279263  -0.5502782   0.04337658  0.87033427]\n",
      "[-0.03893187 -0.74596244  0.06078327  1.1763333 ]\n",
      "[-0.05385112 -0.9418191   0.08430994  1.487435  ]\n",
      "[-0.0726875  -1.1378609   0.11405864  1.8052111 ]\n",
      "[-0.09544472 -1.3340567   0.15016286  2.1310532 ]\n",
      "[-0.12212585 -1.5303158   0.19278392  2.466111  ]\n",
      "[-0.15273216 -1.726471    0.24210614  2.8112211 ]\n",
      "[-0.03030454 -0.16471839  0.03013787  0.31640527]\n",
      "[-0.03359891 -0.36025637  0.03646597  0.61843824]\n",
      "[-0.04080403 -0.5558682   0.04883474  0.92237955]\n",
      "[-0.0519214  -0.75161475  0.06728233  1.230001  ]\n",
      "[-0.06695369 -0.9475347   0.09188235  1.5429821 ]\n",
      "[-0.08590438 -1.143633    0.12274199  1.8628643 ]\n",
      "[-0.10877705 -1.339868    0.15999928  2.1909976 ]\n",
      "[-0.1355744  -1.5361348   0.20381923  2.5284772 ]\n",
      "[-0.16629711 -1.7322491   0.25438878  2.8760684 ]\n",
      "[-0.02881712 -0.18330796  0.04593993  0.27596244]\n",
      "[-0.03248328 -0.37905422  0.05145918  0.5827736 ]\n",
      "[-0.04006436 -0.5748579   0.06311465  0.8912127 ]\n",
      "[-0.05156152 -0.77077675  0.08093891  1.2030492 ]\n",
      "[-0.06697706 -0.96684647  0.10499989  1.519961  ]\n",
      "[-0.08631399 -1.1630692   0.1353991   1.8434875 ]\n",
      "[-0.10957538 -1.3594      0.17226885  2.1749742 ]\n",
      "[-0.13676338 -1.5557308   0.21576834  2.5155082 ]\n",
      "[ 0.024111   -0.23634157 -0.03338672  0.23787203]\n",
      "[ 0.01938417 -0.43097103 -0.02862928  0.51983964]\n",
      "[ 0.01076475 -0.6256785  -0.01823249  0.80336535]\n",
      "[-0.00174882 -0.8205458  -0.00216518  1.0902576 ]\n",
      "[-0.01815974 -1.0156391   0.01963997  1.3822603 ]\n",
      "[-0.03847252 -1.2110006   0.04728518  1.6810198 ]\n",
      "[-0.06269253 -1.4066373   0.08090557  1.9880435 ]\n",
      "[-0.09082527 -1.6025093   0.12066644  2.3046508 ]\n",
      "[-0.12287546 -1.7985134   0.16675946  2.6319091 ]\n",
      "[-0.15884574 -1.9944661   0.21939765  2.970561  ]\n",
      "[ 0.01975843 -0.20952852 -0.02522616  0.24135809]\n",
      "[ 0.01556786 -0.4042812  -0.020399    0.5259785 ]\n",
      "[ 0.00748224 -0.59911025 -0.00987943  0.81216437]\n",
      "[-0.00449997 -0.7940955   0.00636386  1.1017234 ]\n",
      "[-0.02038188 -0.9893006   0.02839833  1.3963962 ]\n",
      "[-0.04016789 -1.184764    0.05632625  1.6978211 ]\n",
      "[-0.06386317 -1.3804884   0.09028267  2.0074933 ]\n",
      "[-0.09147294 -1.5764271   0.13043253  2.3267112 ]\n",
      "[-0.12300148 -1.7724689   0.17696676  2.6565146 ]\n",
      "[-0.15845086 -1.5790588   0.23009706  2.4226875 ]\n",
      "[ 0.01071567 -0.23355822  0.01081957  0.27020174]\n",
      "[ 0.00604451 -0.4288329   0.0162236   0.56627744]\n",
      "[-0.00253215 -0.62417865  0.02754915  0.8640271 ]\n",
      "[-0.01501572 -0.81966454  0.04482969  1.1652431 ]\n",
      "[-0.03140901 -1.0153404   0.06813455  1.4716376 ]\n",
      "[-0.05171582 -1.2112262   0.0975673   1.7848005 ]\n",
      "[-0.07594035 -1.4072998   0.13326332  2.1061513 ]\n",
      "[-0.10408634 -1.6034819   0.17538634  2.436879  ]\n",
      "[-0.13615598 -1.79962     0.22412392  2.7778723 ]\n",
      "[-0.02628796 -0.16651879 -0.00802239  0.32158425]\n",
      "[-0.02961834 -0.3615256  -0.0015907   0.61172646]\n",
      "[-0.03684885 -0.55662525  0.01064382  0.90390795]\n",
      "[-0.04798136 -0.3616491   0.02872198  0.61458945]\n",
      "[-0.05521434 -0.5571604   0.04101377  0.9161785 ]\n",
      "[-0.06635755 -0.7528122   0.05933734  1.2214642 ]\n",
      "[-0.08141379 -0.9486464   0.08376662  1.5321335 ]\n",
      "[-0.10038672 -1.144672    0.1144093   1.8497396 ]\n",
      "[-0.12328016 -1.3408524   0.15140408  2.1756492 ]\n",
      "[-0.1500972  -1.5370895   0.19491707  2.5109804 ]\n",
      "[-0.180839   -1.7332069   0.24513668  2.8565292 ]\n",
      "[-0.01839598 -0.1871733   0.01884663  0.29292962]\n",
      "[-0.02213944 -0.38255882  0.02470522  0.5914964 ]\n",
      "[-0.02979062 -0.5780178   0.03653515  0.891858  ]\n",
      "[-0.04135097 -0.7736158   0.05437231  1.1957982 ]\n",
      "[-0.05682329 -0.96939784  0.07828827  1.5050149 ]\n",
      "[-0.07621124 -1.1653775   0.10838857  1.8210771 ]\n",
      "[-0.0995188  -1.3615237   0.14481011  2.1453738 ]\n",
      "[-0.12674928 -1.5577466   0.18771759  2.479053  ]\n",
      "[-0.15790421 -1.7538792   0.23729865  2.822949  ]\n",
      "[-0.02361588 -0.17057866  0.03644576  0.3228612 ]\n",
      "[-0.02702745 -0.36620012  0.04290298  0.6268112 ]\n",
      "[-0.03435145 -0.5618938   0.0554392   0.9326913 ]\n",
      "[-0.04558933 -0.7577182   0.07409303  1.2422674 ]\n",
      "[-0.06074369 -0.9537088   0.09893838  1.5572101 ]\n",
      "[-0.07981787 -1.1498667   0.13008258  1.8790485 ]\n",
      "[-0.1028152  -1.3461448   0.16766354  2.2091146 ]\n",
      "[-0.1297381  -1.542432    0.21184584  2.548479  ]\n",
      "[-0.0050384  -0.17622463  0.03079775  0.28126922]\n",
      "[-0.00856289 -0.37177205  0.03642314  0.5835044 ]\n",
      "[-0.01599833 -0.56738484  0.04809322  0.88743496]\n",
      "[-0.02734603 -0.7631254   0.06584192  1.1948403 ]\n",
      "[-0.04260854 -0.9590352   0.08973873  1.5074117 ]\n",
      "[-0.06178924 -1.1551234   0.11988696  1.8267082 ]\n",
      "[-0.08489171 -1.3513534   0.15642112  2.154103  ]\n",
      "[-0.11191878 -1.5476285   0.19950318  2.4907217 ]\n",
      "[-0.14287135 -1.7437732   0.24931762  2.8373685 ]\n",
      "[-0.00166755 -0.21594884 -0.00908944  0.31477195]\n",
      "[-0.00598653 -0.41094014 -0.002794    0.60457456]\n",
      "[-0.01420533 -0.6060229   0.00929749  0.89637613]\n",
      "[-0.02632579 -0.80126965  0.02722501  1.191967  ]\n",
      "[-0.04235118 -0.99673355  0.05106435  1.4930574 ]\n",
      "[-0.06228585 -1.1924382   0.0809255   1.8012382 ]\n",
      "[-0.08613462 -1.3883661   0.11695027  2.1179345 ]\n",
      "[-0.11390194 -1.5844442   0.15930896  2.4443474 ]\n",
      "[-0.14559083 -1.7805265   0.2081959   2.7813854 ]\n",
      "[-0.18120135 -1.9763765   0.2638236   3.1295848 ]\n",
      "[ 0.04936605 -0.21615462  0.03643093  0.27692524]\n",
      "[ 0.04504296 -0.41177687  0.04196944  0.58087224]\n",
      "[ 0.03680743 -0.607461    0.05358688  0.8864753 ]\n",
      "[ 0.0246582  -0.41310582  0.07131639  0.61110806]\n",
      "[ 0.01639609 -0.6091483   0.08353855  0.92537355]\n",
      "[ 0.00421312 -0.8052931   0.10204602  1.2430965 ]\n",
      "[-0.01189274 -1.0015658   0.12690794  1.5659235 ]\n",
      "[-0.03192405 -1.1979554   0.15822642  1.8953496 ]\n",
      "[-0.05588316 -1.3943996   0.1961334   2.23266   ]\n",
      "[-0.08377115 -1.5907695   0.24078661  2.5788615 ]\n",
      "[ 0.04328598 -0.21979907 -0.02653761  0.23860091]\n",
      "[ 0.03888999 -0.41453207 -0.02176559  0.5227964 ]\n",
      "[ 0.03059935 -0.609341   -0.01130966  0.808542  ]\n",
      "[ 0.01841253 -0.80430615  0.00486118  1.0976461 ]\n",
      "[ 0.00232641 -0.9994918   0.0268141   1.3918502 ]\n",
      "[-0.01766343 -0.8047138   0.05465111  1.1076707 ]\n",
      "[-0.0337577  -1.0005099   0.07680452  1.4169856 ]\n",
      "[-0.0537679  -1.1964942   0.10514423  1.732654  ]\n",
      "[-0.07769778 -1.3926475   0.13979732  2.0561144 ]\n",
      "[-0.10555073 -1.5888948   0.1809196   2.3885803 ]\n",
      "[-0.13732862 -1.7850888   0.2286912   2.7309687 ]\n",
      "[-0.04189654 -0.23268196  0.01512487  0.3083249 ]\n",
      "[-0.04655018 -0.42801613  0.02129137  0.6057392 ]\n",
      "[-0.0551105  -0.62342924  0.03340615  0.9050516 ]\n",
      "[-0.06757909 -0.81898725  0.05150719  1.2080445 ]\n",
      "[-0.08395883 -1.0147353   0.07566807  1.5164137 ]\n",
      "[-0.10425354 -1.2106868   0.10599635  1.831725  ]\n",
      "[-0.12846728 -1.4068106   0.14263085  2.1553643 ]\n",
      "[-0.15660349 -1.6030161   0.18573813  2.4884753 ]\n",
      "[-0.18866381 -1.7991359   0.23550764  2.8318887 ]\n",
      "[-0.04254669 -0.18501844  0.02571187  0.33578435]\n",
      "[-0.04624706 -0.38049668  0.03242755  0.6364633 ]\n",
      "[-0.05385699 -0.5760555   0.04515682  0.9391793 ]\n",
      "[-0.06537811 -0.7717562   0.06394041  1.2457026 ]\n",
      "[-0.08081323 -0.96763736  0.08885446  1.5577097 ]\n",
      "[-0.10016598 -1.1637039   0.12000865  1.8767382 ]\n",
      "[-0.12344005 -1.3599133   0.15754342  2.2041333 ]\n",
      "[-0.15063831 -1.1666181   0.20162608  1.9639076 ]\n",
      "[-0.17397068 -1.3632234   0.24090424  2.3117187 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02169101 -0.16214462 -0.03603952  0.3306894 ]\n",
      "[ 0.01844812 -0.35673553 -0.02942573  0.61179286]\n",
      "[ 0.01131341 -0.5514341  -0.01718988  0.8950644 ]\n",
      "[ 2.8472734e-04 -7.4631882e-01  7.1141386e-04  1.1822947e+00]\n",
      "[-0.01464165 -0.94145     0.02435731  1.4752005 ]\n",
      "[-0.03347065 -1.136861    0.05386132  1.7753904 ]\n",
      "[-0.05620787 -1.3325468   0.08936913  2.084321  ]\n",
      "[-0.0828588  -1.5284512   0.13105555  2.4032445 ]\n",
      "[-0.11342783 -1.7244499   0.17912044  2.7331417 ]\n",
      "[-0.14791682 -1.9203327   0.23378326  3.074645  ]\n",
      "[ 0.01276363 -0.20435172  0.04960406  0.29947105]\n",
      "[ 0.00867659 -0.40014434  0.05559348  0.60737634]\n",
      "[ 0.00067371 -0.20584193  0.06774101  0.33270907]\n",
      "[-0.00344313 -0.4018594   0.07439519  0.6459615 ]\n",
      "[-0.01148032 -0.59793484  0.08731442  0.96111315]\n",
      "[-0.02343902 -0.40408802  0.10653669  0.6970885 ]\n",
      "[-0.03152078 -0.6005134   0.12047846  1.0213186 ]\n",
      "[-0.04353105 -0.7970165   0.14090483  1.3492718 ]\n",
      "[-0.05947138 -0.9935995   0.16789027  1.6825129 ]\n",
      "[-0.07934336 -1.190221    0.20154051  2.0224264 ]\n",
      "[-0.10314778 -1.3867805   0.24198905  2.3701506 ]\n",
      "[ 0.03962031 -0.15256259  0.00236839  0.31621033]\n",
      "[ 0.03656906 -0.3477182   0.0086926   0.6096392 ]\n",
      "[ 0.02961469 -0.5429606   0.02088538  0.9050473 ]\n",
      "[ 0.01875548 -0.73835903  0.03898633  1.2042209 ]\n",
      "[ 0.0039883  -0.93396264  0.06307074  1.5088625 ]\n",
      "[-0.01469095 -1.1297898   0.09324799  1.8205497 ]\n",
      "[-0.03728675 -1.3258159   0.129659    2.1406865 ]\n",
      "[-0.06380307 -1.5219586   0.17247273  2.470444  ]\n",
      "[-0.09424224 -1.7180609   0.2218816   2.8106892 ]\n",
      "[ 0.04964727 -0.16885357 -0.01069161  0.25848544]\n",
      "[ 0.0462702  -0.36382127 -0.0055219   0.547777  ]\n",
      "[ 0.03899378 -0.5588652   0.00543364  0.838715  ]\n",
      "[ 0.02781647 -0.7540609   0.02220794  1.1331018 ]\n",
      "[ 0.01273525 -0.9494664   0.04486997  1.4326663 ]\n",
      "[-0.00625408 -1.1451124   0.0735233   1.7390273 ]\n",
      "[-0.02915632 -1.3409909   0.10830384  2.0536475 ]\n",
      "[-0.05597614 -1.5370415   0.1493768   2.3777797 ]\n",
      "[-0.08671697 -1.7331355   0.19693239  2.7123985 ]\n",
      "[-0.12137968 -1.929056    0.25118035  3.0581238 ]\n",
      "[-0.03657585 -0.15680395 -0.02506913  0.33235982]\n",
      "[-0.03971193 -0.35156026 -0.01842193  0.61703295]\n",
      "[-0.04674314 -0.5464201  -0.00608128  0.90385735]\n",
      "[-0.05767154 -0.74145913  0.01199587  1.1946226 ]\n",
      "[-0.07250072 -0.9367344   0.03588832  1.4910411 ]\n",
      "[-0.09123541 -1.1322743   0.06570914  1.7947111 ]\n",
      "[-0.1138809  -1.3280678   0.10160337  2.107072  ]\n",
      "[-0.14044225 -1.52405     0.14374481  2.4293494 ]\n",
      "[-0.17092325 -1.7200861   0.19233179  2.7624862 ]\n",
      "[-0.20532498 -1.9159521   0.24758153  3.1070654 ]\n",
      "[-0.02934095 -0.2167934   0.01507994  0.3273587 ]\n",
      "[-0.03367682 -0.41212675  0.02162711  0.6247588 ]\n",
      "[-0.04191935 -0.6075439   0.03412228  0.9241737 ]\n",
      "[-0.05407023 -0.8031097   0.05260576  1.2273817 ]\n",
      "[-0.07013243 -0.9988678   0.07715339  1.5360717 ]\n",
      "[-0.09010978 -1.1948292   0.10787483  1.8518    ]\n",
      "[-0.11400637 -1.3909597   0.14491083  2.1759393 ]\n",
      "[-0.14182557 -1.5871646   0.18842961  2.5096169 ]\n",
      "[-0.17356886 -1.783271    0.23862195  2.8536406 ]\n",
      "[-0.00598037 -0.16387144 -0.01083108  0.27722996]\n",
      "[-0.0092578  -0.35883722 -0.00528648  0.5664772 ]\n",
      "[-0.01643455 -0.5538846   0.00604306  0.85748994]\n",
      "[-0.02751224 -0.74908835  0.02319286  1.152067  ]\n",
      "[-0.04249401 -0.9445051   0.0462342   1.4519312 ]\n",
      "[-0.06138411 -1.1401635   0.07527282  1.7586933 ]\n",
      "[-0.08418738 -1.3360529   0.11044669  2.0738046 ]\n",
      "[-0.11090843 -1.5321093   0.15192278  2.3985026 ]\n",
      "[-0.14155062 -1.7281986   0.19989283  2.7337425 ]\n",
      "[-0.17611459 -1.9240986   0.25456768  3.0801194 ]\n",
      "[ 0.0355942   0.19274235  0.00542477 -0.24209656]\n",
      "[ 0.03944904 -0.00245666  0.00058283  0.05229253]\n",
      "[ 0.03939991 -0.19758697  0.00162869  0.3451593 ]\n",
      "[ 0.03544817 -0.39273205  0.00853187  0.6383554 ]\n",
      "[ 0.02759353 -0.5879719   0.02129898  0.93371284]\n",
      "[ 0.01583409 -0.78337467  0.03997324  1.2330118 ]\n",
      "[ 1.6659906e-04 -9.7898710e-01  6.4633474e-02  1.5379452e+00]\n",
      "[-0.01941314 -1.1748246   0.09539238  1.850077  ]\n",
      "[-0.04290964 -0.9808731   0.13239391  1.5884753 ]\n",
      "[-0.0625271  -1.1772963   0.16416343  1.9193419 ]\n",
      "[-0.08607303 -1.3737592   0.20255026  2.2581217 ]\n",
      "[-0.1135482 -1.570125   0.2477127  2.6057923]\n"
     ]
    }
   ],
   "source": [
    "# env.render()\n",
    "for ep in range(EPSILON_NUM):\n",
    "    last_observation = env.reset()\n",
    "    total_rewards = 0\n",
    "    index = 0\n",
    "    while True:\n",
    "        action = model.predict(last_observation)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        # print(observation)\n",
    "        total_rewards += 1 \n",
    "        index += 1\n",
    "        model.store_transition(last_observation, action, reward, observation)\n",
    "        last_observation = observation\n",
    "        if done:\n",
    "            print(f\"epsilon:{ep}, reward:{total_rewards}\")\n",
    "            model.train()\n",
    "            total_rewards = 0\n",
    "            break\n",
    "        if index > THRESHOLD:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b614b952",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243d29a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
